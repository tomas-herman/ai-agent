{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL and save directory\n",
    "url = \"https://www.youtube.com/watch?v=KwR3nxojS0g\"\n",
    "save_dir = \"docs/youtube/\"\n",
    "\n",
    "# Function to generate transcript filename from URL\n",
    "def generate_transcript_filename(url):\n",
    "    parsed_url = urllib.parse.urlparse(url)\n",
    "    video_id = urllib.parse.parse_qs(parsed_url.query).get('v', [None])[0]\n",
    "    if video_id is None:\n",
    "        raise ValueError(\"Unable to extract video ID from URL\")\n",
    "    return os.path.join(save_dir, f\"transcript_{video_id}.json\")\n",
    "\n",
    "transcript_filename = generate_transcript_filename(url)\n",
    "\n",
    "# Check if transcript already exists\n",
    "if os.path.exists(transcript_filename):\n",
    "    # Load the existing transcript\n",
    "    with open(transcript_filename, 'r', encoding='utf-8') as file:\n",
    "        docs = json.load(file)\n",
    "else:\n",
    "    # Download video, create transcript, and save it\n",
    "    loader = GenericLoader(\n",
    "        YoutubeAudioLoader([url], save_dir),\n",
    "        OpenAIWhisperParser()\n",
    "    )\n",
    "    docs = loader.load()\n",
    "\n",
    "    # Convert docs to a JSON-compatible format\n",
    "    docs_json = [{'page_content': doc.page_content, 'metadata': doc.metadata} for doc in docs]\n",
    "\n",
    "    # Save the transcript and metadata as JSON\n",
    "    with open(transcript_filename, 'w', encoding='utf-8') as file:\n",
    "        json.dump(docs_json, file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in docs:\n",
    "    print(doc[\"page_content\"])"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
